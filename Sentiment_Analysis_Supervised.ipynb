{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DTnpfuB6CCCP"
   },
   "source": [
    "# Import necessary depencencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_DyF3ZwACCCV"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import text_normalizer as tn\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=2, linewidth=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KV_2XMDJCCCW"
   },
   "source": [
    "# Load and normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_if5EXlJCCCW",
    "outputId": "41510511-d79e-43d0-8455-179c0c75236b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review sentiment\n",
      "0  One of the other reviewers has mentioned that ...  positive\n",
      "1  A wonderful little production. <br /><br />The...  positive\n",
      "2  I thought this was a wonderful way to spend ti...  positive\n",
      "3  Basically there's a family where a little boy ...  negative\n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(r'movie_reviews.csv')\n",
    "\n",
    "# take a peek at the data\n",
    "print(dataset.head())\n",
    "reviews = np.array(dataset['review'])\n",
    "sentiments = np.array(dataset['sentiment'])\n",
    "\n",
    "# build train and test datasets\n",
    "train_reviews = reviews[:35000]\n",
    "train_sentiments = sentiments[:35000]\n",
    "test_reviews = reviews[35000:]\n",
    "test_sentiments = sentiments[35000:]\n",
    "\n",
    "# normalize datasets\n",
    "norm_train_reviews = tn.normalize_corpus(train_reviews)\n",
    "norm_test_reviews = tn.normalize_corpus(test_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9fjialg2CCCX"
   },
   "source": [
    "# Traditional Supervised Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vBDzPreqCCCY"
   },
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "H-ShYJxQCCCY"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# build BOW features on train reviews\n",
    "cv = CountVectorizer(binary=False, min_df=0.0, max_df=1.0, ngram_range=(1,2))\n",
    "cv_train_features = cv.fit_transform(norm_train_reviews)\n",
    "\n",
    "# build TFIDF features on train reviews\n",
    "tv = TfidfVectorizer(use_idf=True, min_df=0.0, max_df=1.0, ngram_range=(1,2),\n",
    "                     sublinear_tf=True)\n",
    "tv_train_features = tv.fit_transform(norm_train_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "Ek0NDUi4CCCY"
   },
   "outputs": [],
   "source": [
    "# transform test reviews into features\n",
    "cv_test_features = cv.transform(norm_test_reviews)\n",
    "tv_test_features = tv.transform(norm_test_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "36fbIeNPCCCZ",
    "outputId": "4ce2a93e-b7d7-4c9e-f7cb-8709eaca8bd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW model:> Train features shape: (35000, 2114022)  Test features shape: (15000, 2114022)\n",
      "TFIDF model:> Train features shape: (35000, 2114022)  Test features shape: (15000, 2114022)\n"
     ]
    }
   ],
   "source": [
    "print('BOW model:> Train features shape:', cv_train_features.shape, ' Test features shape:', cv_test_features.shape)\n",
    "print('TFIDF model:> Train features shape:', tv_train_features.shape, ' Test features shape:', tv_test_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sYePwjDyCCCZ"
   },
   "source": [
    "## Model Training, Prediction and Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "c7UxAUsuCCCZ"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(penalty='l2', max_iter=100, C=1)\n",
    "svm = SGDClassifier(loss='hinge', max_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IsjKG8ZLCCCa",
    "outputId": "d647e8ec-b76c-428e-fe52-3b97f29c3dfe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance metrics:\n",
      "------------------------------\n",
      "Accuracy: 0.91\n",
      "Precision: 0.91\n",
      "Recall: 0.91\n",
      "F1 Score: 0.91\n",
      "\n",
      "Model Classification report:\n",
      "------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   positive       0.90      0.91      0.91      7510\n",
      "   negative       0.91      0.90      0.90      7490\n",
      "\n",
      "avg / total       0.91      0.91      0.91     15000\n",
      "\n",
      "\n",
      "Prediction Confusion Matrix:\n",
      "------------------------------\n",
      "                 Predicted:         \n",
      "                   positive negative\n",
      "Actual: positive       6817      693\n",
      "        negative        731     6759\n"
     ]
    }
   ],
   "source": [
    " lr_bow_predictions = meu.train_predict_model(classifier=lr, \n",
    "                                             train_features=cv_train_features, train_labels=train_sentiments,\n",
    "                                             test_features=cv_test_features, test_labels=test_sentiments)\n",
    "meu.display_model_performance_metrics(true_labels=test_sentiments, predicted_labels=lr_bow_predictions,\n",
    "                                      classes=['positive', 'negative'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OH7nAw50CCCa",
    "outputId": "1694764d-3bf2-4088-db28-c7ec5f7b2456",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance metrics:\n",
      "------------------------------\n",
      "Accuracy: 0.9\n",
      "Precision: 0.9\n",
      "Recall: 0.9\n",
      "F1 Score: 0.9\n",
      "\n",
      "Model Classification report:\n",
      "------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   positive       0.89      0.90      0.90      7510\n",
      "   negative       0.90      0.89      0.90      7490\n",
      "\n",
      "avg / total       0.90      0.90      0.90     15000\n",
      "\n",
      "\n",
      "Prediction Confusion Matrix:\n",
      "------------------------------\n",
      "                 Predicted:         \n",
      "                   positive negative\n",
      "Actual: positive       6780      730\n",
      "        negative        828     6662\n"
     ]
    }
   ],
   "source": [
    "lr_tfidf_predictions = meu.train_predict_model(classifier=lr, \n",
    "                                               train_features=tv_train_features, train_labels=train_sentiments,\n",
    "                                               test_features=tv_test_features, test_labels=test_sentiments)\n",
    "meu.display_model_performance_metrics(true_labels=test_sentiments, predicted_labels=lr_tfidf_predictions,\n",
    "                                      classes=['positive', 'negative'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7zDB3QzlCCCa",
    "outputId": "bbc854d3-3a3a-4e4a-8f21-cedd1372d351"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance metrics:\n",
      "------------------------------\n",
      "Accuracy: 0.9\n",
      "Precision: 0.9\n",
      "Recall: 0.9\n",
      "F1 Score: 0.9\n",
      "\n",
      "Model Classification report:\n",
      "------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   positive       0.90      0.89      0.90      7510\n",
      "   negative       0.90      0.91      0.90      7490\n",
      "\n",
      "avg / total       0.90      0.90      0.90     15000\n",
      "\n",
      "\n",
      "Prediction Confusion Matrix:\n",
      "------------------------------\n",
      "                 Predicted:         \n",
      "                   positive negative\n",
      "Actual: positive       6721      789\n",
      "        negative        711     6779\n"
     ]
    }
   ],
   "source": [
    "svm_bow_predictions = meu.train_predict_model(classifier=svm, \n",
    "                                             train_features=cv_train_features, train_labels=train_sentiments,\n",
    "                                             test_features=cv_test_features, test_labels=test_sentiments)\n",
    "meu.display_model_performance_metrics(true_labels=test_sentiments, \n",
    "                                      predicted_labels=svm_bow_predictions,\n",
    "                                      classes=['positive', 'negative'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hqjZ1Es7CCCb",
    "outputId": "3cb021b9-5c06-498b-a0c6-680785d22cba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance metrics:\n",
      "------------------------------\n",
      "Accuracy: 0.9\n",
      "Precision: 0.9\n",
      "Recall: 0.9\n",
      "F1 Score: 0.9\n",
      "\n",
      "Model Classification report:\n",
      "------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   positive       0.89      0.91      0.90      7510\n",
      "   negative       0.91      0.88      0.90      7490\n",
      "\n",
      "avg / total       0.90      0.90      0.90     15000\n",
      "\n",
      "\n",
      "Prediction Confusion Matrix:\n",
      "------------------------------\n",
      "                 Predicted:         \n",
      "                   positive negative\n",
      "Actual: positive       6839      671\n",
      "        negative        871     6619\n"
     ]
    }
   ],
   "source": [
    "svm_tfidf_predictions = meu.train_predict_model(classifier=svm, \n",
    "                                                train_features=tv_train_features, train_labels=train_sentiments,\n",
    "                                                test_features=tv_test_features, test_labels=test_sentiments)\n",
    "meu.display_model_performance_metrics(true_labels=test_sentiments, \n",
    "                                      predicted_labels=svm_tfidf_predictions,\n",
    "                                      classes=['positive', 'negative'])\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "name": "Sentiment Analysis - Supervised.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
